{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('50_startups.csv')\n",
    "dataset\n",
    "x = dataset.iloc[:, :-1].values \n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for finding the index of max value in an array\n",
    "def max_pvalue_index(p):\n",
    "    for i,j in enumerate(p):\n",
    "        if j == max(p):\n",
    "            return i;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "categories='auto'\n",
    "# preprocessor = make_column_transformer( (OneHotEncoder(),[3]),\n",
    "#                                        remainder=\"passthrough\")\n",
    "preprocessor =ColumnTransformer(\n",
    "    [('one_hot_encoder', OneHotEncoder(), [3])],    # The column numbers to be transformed (here is [0] but can be [0, 1, 3])\n",
    "    remainder='passthrough'                         # Leave the rest of the columns untouched\n",
    ")\n",
    "x = preprocessor.fit_transform(x)\n",
    "\n",
    "#encoding y variable if it was a character variable \n",
    "# labelencoder_y = LabelEncoder()\n",
    "# y = labelencoder_y.fit_transform(y)\n",
    "\n",
    "#avoiding the dummy variabe trap\n",
    "x = x[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9761184704518228\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.explained_variance_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arr, values and axis are three modules of np.append\\n    arr is the primary array and values is the array to append\\n    if axis = 0 the array would be appended row wise and for 1 column wise\\n    now as we need ones in the first column for backward elimination the column of ones has been set as the primary array\\n    then the x array has been appended to it'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#backward elimination starts here\n",
    "# import statsmodels.formula.api as sm  OLS is not a class of formula.api rather it belongs to statsmodels.api now\n",
    "x = np.append(arr = np.ones((x.shape[0],1)), values = x, axis = 1)\n",
    "\"\"\"arr, values and axis are three modules of np.append\n",
    "    arr is the primary array and values is the array to append\n",
    "    if axis = 0 the array would be appended row wise and for 1 column wise\n",
    "    now as we need ones in the first column for backward elimination the column of ones has been set as the primary array\n",
    "    then the x array has been appended to it\"\"\"\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.impute import SimpleImputer #object declaration\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(x[:, 0:6])\n",
    "x[:, 0:6] = imputer.transform(x[:, 0:6])\n",
    "x \n",
    "X = np.array(x, dtype=float) #data type of x was object initialy. it has to be of int or float type otherwise the ols of statsmodel won't work\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwardelimination_pvalues(x_opt,S_L):\n",
    "    size = x_opt.shape[1]\n",
    "    for i in range(0,size):\n",
    "        regressor_ols = sm.OLS(endog = y, exog = x_opt).fit() #OLS = ordinary least squares\n",
    "        result = regressor_ols.summary()\n",
    "        p = max_pvalue_index(regressor_ols.pvalues[0:x_opt.shape[1]])\n",
    "#         print(p)\n",
    "        if p<S_L:\n",
    "            break\n",
    "\n",
    "        x_opt = np.delete(x_opt, p, axis=1)\n",
    "    return x_opt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 1.6534920e+05],\n",
       "       [1.0000000e+00, 1.6259770e+05],\n",
       "       [1.0000000e+00, 1.5344151e+05],\n",
       "       [1.0000000e+00, 1.4437241e+05],\n",
       "       [1.0000000e+00, 1.4210734e+05],\n",
       "       [1.0000000e+00, 1.3187690e+05],\n",
       "       [1.0000000e+00, 1.3461546e+05],\n",
       "       [1.0000000e+00, 1.3029813e+05],\n",
       "       [1.0000000e+00, 1.2054252e+05],\n",
       "       [1.0000000e+00, 1.2333488e+05],\n",
       "       [1.0000000e+00, 1.0191308e+05],\n",
       "       [1.0000000e+00, 1.0067196e+05],\n",
       "       [1.0000000e+00, 9.3863750e+04],\n",
       "       [1.0000000e+00, 9.1992390e+04],\n",
       "       [1.0000000e+00, 1.1994324e+05],\n",
       "       [1.0000000e+00, 1.1452361e+05],\n",
       "       [1.0000000e+00, 7.8013110e+04],\n",
       "       [1.0000000e+00, 9.4657160e+04],\n",
       "       [1.0000000e+00, 9.1749160e+04],\n",
       "       [1.0000000e+00, 8.6419700e+04],\n",
       "       [1.0000000e+00, 7.6253860e+04],\n",
       "       [1.0000000e+00, 7.8389470e+04],\n",
       "       [1.0000000e+00, 7.3994560e+04],\n",
       "       [1.0000000e+00, 6.7532530e+04],\n",
       "       [1.0000000e+00, 7.7044010e+04],\n",
       "       [1.0000000e+00, 6.4664710e+04],\n",
       "       [1.0000000e+00, 7.5328870e+04],\n",
       "       [1.0000000e+00, 7.2107600e+04],\n",
       "       [1.0000000e+00, 6.6051520e+04],\n",
       "       [1.0000000e+00, 6.5605480e+04],\n",
       "       [1.0000000e+00, 6.1994480e+04],\n",
       "       [1.0000000e+00, 6.1136380e+04],\n",
       "       [1.0000000e+00, 6.3408860e+04],\n",
       "       [1.0000000e+00, 5.5493950e+04],\n",
       "       [1.0000000e+00, 4.6426070e+04],\n",
       "       [1.0000000e+00, 4.6014020e+04],\n",
       "       [1.0000000e+00, 2.8663760e+04],\n",
       "       [1.0000000e+00, 4.4069950e+04],\n",
       "       [1.0000000e+00, 2.0229590e+04],\n",
       "       [1.0000000e+00, 3.8558510e+04],\n",
       "       [1.0000000e+00, 2.8754330e+04],\n",
       "       [1.0000000e+00, 2.7892920e+04],\n",
       "       [1.0000000e+00, 2.3640930e+04],\n",
       "       [1.0000000e+00, 1.5505730e+04],\n",
       "       [1.0000000e+00, 2.2177740e+04],\n",
       "       [1.0000000e+00, 1.0002300e+03],\n",
       "       [1.0000000e+00, 1.3154600e+03],\n",
       "       [1.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 5.4205000e+02],\n",
       "       [1.0000000e+00, 0.0000000e+00]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import statsmodels as sm\n",
    "x_opt = X[:,:] # we took 1 2 3 4 5 individually so that we can 'manually' eliminate them \n",
    "S_L = .05\n",
    "backwardelimination_pvalues(x_opt,S_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
